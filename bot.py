### ğŸ“¦ æ¨¡çµ„èˆ‡å¥—ä»¶åŒ¯å…¥
import discord
from openai import OpenAI
import os, requests, datetime, base64
import fitz  # è™•ç† PDF æª”æ¡ˆ (PyMuPDF)
import psycopg2
from psycopg2.extras import RealDictCursor, Json
from psycopg2 import pool
import json
import tiktoken


### ğŸ” è¼‰å…¥ç’°å¢ƒè®Šæ•¸èˆ‡é‡‘é‘°
DISCORD_TOKEN = os.getenv("DISCORD_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY")
DATABASE_URL = os.getenv("DATABASE_URL")


### ğŸ›¢ï¸ PostgreSQL è³‡æ–™åº«é€£ç·šæ± è¨­å®š
db_pool = pool.SimpleConnectionPool(
    minconn=1,
    maxconn=10,
    dsn=DATABASE_URL,
    cursor_factory=RealDictCursor
)

def get_db_connection():
    return db_pool.getconn()


### ğŸ§  ä½¿ç”¨è€…é•·æœŸè¨˜æ†¶å­˜å–

def load_user_memory(user_id):
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("""
        SELECT summary, history, token_accum, last_response_id, thread_count
        FROM memory
        WHERE user_id = %s
    """, (user_id,))
    row = cursor.fetchone()
    db_pool.putconn(conn)

    if row:
        return {
            "summary": row["summary"],
            "history": row["history"],
            "token_accum": row["token_accum"],
            "last_response_id": row["last_response_id"],
            "thread_count": row["thread_count"] or 0
        }
    else:
        return {
            "summary": "",
            "history": [],
            "token_accum": 0,
            "last_response_id": None,
            "thread_count": 0
        }

def save_user_memory(user_id, state):
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("""
        INSERT INTO memory (user_id, summary, token_accum, last_response_id, thread_count)
        VALUES (%s, %s, %s, %s, %s)
        ON CONFLICT (user_id) DO UPDATE SET
            summary = EXCLUDED.summary,
            token_accum = EXCLUDED.token_accum,
            last_response_id = EXCLUDED.last_response_id,
            thread_count = EXCLUDED.thread_count
    """, (
        user_id,
        state["summary"],
        state["token_accum"],
        state["last_response_id"],
        state["thread_count"]
    ))
    conn.commit()
    db_pool.putconn(conn)


### ğŸ—ï¸ åˆå§‹è³‡æ–™è¡¨å»ºæ§‹èˆ‡åŠŸèƒ½ä½¿ç”¨è¨˜éŒ„çµ±è¨ˆ
def init_db():
    conn = get_db_connection()
    cur = conn.cursor()

    cur.execute("""
        CREATE TABLE IF NOT EXISTS memory (
            user_id TEXT PRIMARY KEY,
            summary TEXT,
            history JSONB,
            token_accum INTEGER,
            last_response_id TEXT,
            thread_count INTEGER
        )
    """)

    cur.execute("""
        CREATE TABLE IF NOT EXISTS feature_usage (
            feature TEXT PRIMARY KEY,
            count INTEGER NOT NULL,
            date DATE NOT NULL
        )
    """)

    for feature in ["æ¨ç†", "å•", "æ•´ç†", "æœå°‹"]:
        cur.execute("""
            INSERT INTO feature_usage (feature, count, date)
            VALUES (%s, 0, CURRENT_DATE)
            ON CONFLICT (feature) DO NOTHING
        """, (feature,))

    conn.commit()
    db_pool.putconn(conn)

def record_usage(feature_name):
    conn = get_db_connection()
    cur = conn.cursor()
    today = datetime.date.today()
    cur.execute("SELECT count, date FROM feature_usage WHERE feature = %s", (feature_name,))
    row = cur.fetchone()
    if row:
        if row["date"] != today:
            cur.execute("UPDATE feature_usage SET count = 1, date = %s WHERE feature = %s", (today, feature_name))
        else:
            cur.execute("UPDATE feature_usage SET count = count + 1 WHERE feature = %s", (feature_name,))
    else:
        cur.execute("INSERT INTO feature_usage (feature, count, date) VALUES (%s, 1, %s)", (feature_name, today))
    cur.execute("SELECT count FROM feature_usage WHERE feature = %s", (feature_name,))
    updated = cur.fetchone()["count"]
    conn.commit()
    db_pool.putconn(conn)
    return updated

def is_usage_exceeded(feature_name, limit=20):
    conn = get_db_connection()
    cur = conn.cursor()
    today = datetime.date.today()
    cur.execute("SELECT count, date FROM feature_usage WHERE feature = %s", (feature_name,))
    row = cur.fetchone()
    db_pool.putconn(conn)
    if row:
        return row["date"] == today and row["count"] >= limit
    return False


### ğŸ¤– æ¨¡å‹èˆ‡æç¤ºè©è¨­å®š
SYSTEM_PROMPT = (
    "ä½ æ˜¯æ“æœ‰é•·æœŸè¨˜æ†¶çš„ AI åŠ©ç†ï¼Œèƒ½å¤ ç†è§£ä¸¦å»¶çºŒä½¿ç”¨è€…çš„å°è©±æ„åœ–èˆ‡æƒ…å¢ƒã€‚"
    "ç•¶ä½ çœ‹åˆ°ã€è¨˜æ†¶æ‘˜è¦ï¼š...ã€æ™‚ï¼Œè«‹å–„ç”¨é€™æ®µæ‘˜è¦ä¾†ç†è§£ä¸Šä¸‹æ–‡ã€‚"
    "è«‹ä½¿ç”¨zn-TWï¼Œå›ç­”ç°¡æ½”æœ‰æ¢ç†ï¼Œå¿…è¦æ™‚å¯ä»¥è£œå……æ­·å²èƒŒæ™¯æˆ–å»¶çºŒä¹‹å‰çš„è©±é¡Œã€‚"
)

client_ai = OpenAI(api_key=OPENAI_API_KEY)
client_perplexity = OpenAI(api_key=PERPLEXITY_API_KEY, base_url="https://api.perplexity.ai")

### ğŸ’¬ Discord Bot åˆå§‹åŒ–èˆ‡äº‹ä»¶ç¶å®š
intents = discord.Intents.default()
intents.message_content = True
intents.messages = True
intents.guilds = True
client = discord.Client(intents=intents)

@client.event
async def on_ready():
    init_db()
    print(f'âœ… Bot ç™»å…¥æˆåŠŸï¼š{client.user}')


### ğŸ”¢ Token è¨ˆç®—èˆ‡æ‘˜è¦è¼”åŠ©
ENCODER = tiktoken.encoding_for_model("gpt-4o-mini")

def count_tokens(text):
    return len(ENCODER.encode(text))

def summarize_history(history):
    history_text = "\n".join(f"{m['role']}: {m['content']}" for m in history)
    response = client_ai.responses.create(
        model="gpt-4o-mini",
        input=[
            {"role": "system", "content": "è«‹å°‡ä»¥ä¸‹å¤šè¼ªå°è©±è½‰æ›ç‚º AI åŠ©ç†å¯ä»¥ç†è§£çš„é•·æœŸè¨˜æ†¶å…§å®¹ï¼Œè«‹ä»¥å‚™å¿˜éŒ„å½¢å¼ç°¡è¿°ä½¿ç”¨è€…çš„å€‹æ€§ã€æå•ä¸»é¡Œã€èƒŒæ™¯è³‡è¨Šã€èªæ°£èˆ‡éœ€æ±‚ã€‚"},
            {"role": "user", "content": history_text}
        ],
        max_output_tokens=500
    )
    return response.output_text

pending_reset_confirmations = {}
@client.event
async def on_message(message):
    if message.author == client.user:
        return

    commands = message.content.split("!")
    for cmd in commands:
        if not cmd.strip():
            continue

        # --- åŠŸèƒ½ 1ï¼šæ¨ç† ---
        if cmd.startswith("æ¨ç† "):
            prompt = cmd[3:].strip()
            thinking_message = await message.reply("ğŸ§  Thinking...")

            try:
                user_id = f"{message.guild.id}-{message.author.id}" if message.guild else f"dm-{message.author.id}"
                state = load_user_memory(user_id)

                # âœ… åˆå§‹åŒ– thread_count è‹¥ä¸å­˜åœ¨
                if "thread_count" not in state:
                    state["thread_count"] = 0

                # âœ… æ¯æ¬¡å°è©±è¨ˆæ•¸ +1
                state["thread_count"] += 1

                # âœ… è‹¥æ»¿ 10 è¼ªï¼Œç”¢ç”Ÿæ‘˜è¦ã€é‡ç½®å›åˆæ•¸èˆ‡å°è©± ID
                if state["thread_count"] >= 10 and state["last_response_id"]:
                    response = client_ai.responses.create(
                        model="gpt-4o",
                        previous_response_id=state["last_response_id"],
                        input=[{
                            "role": "user",
                            "content": (
                                "è«‹æ ¹æ“šæ•´æ®µå°è©±ï¼Œæ¿ƒç¸®ç‚ºä¸€æ®µå¹«åŠ© AI å»¶çºŒå°è©±çš„è¨˜æ†¶æ‘˜è¦ï¼Œ"
                                "æ‘˜è¦ä¸­æ‡‰åŒ…å«ä½¿ç”¨è€…çš„ä¸»è¦ç›®æ¨™ã€å•é¡Œé¡å‹ã€èªæ°£ç‰¹å¾µèˆ‡é‡è¦èƒŒæ™¯çŸ¥è­˜ï¼Œ"
                                "è®“ AI èƒ½ä»¥æ­¤ç‚ºåŸºç¤ç¹¼çºŒèˆ‡ä½¿ç”¨è€…æºé€šã€‚"
                            )
                        }],
                        store=False
                    )
                    state["summary"] = response.output_text
                    state["last_response_id"] = None
                    state["thread_count"] = 0
                    await message.channel.send("ğŸ“ å°è©±å·²é” 10 è¼ªï¼Œå·²è‡ªå‹•ç¸½çµä¸¦é‡æ–°é–‹å§‹ã€‚")

                # âœ… æº–å‚™æ–°çš„ promptï¼ˆå«æ‘˜è¦ï¼‰
                input_prompt = []
                if state["summary"]:
                    input_prompt.append({
                        "role": "system",
                        "content": f"é€™æ˜¯å‰æ®µæ‘˜è¦ï¼š{state['summary']}"
                    })
                input_prompt.append({
                    "role": "user",
                    "content": prompt
                })

                # âœ… é–‹å§‹æ–°ä¸€è¼ªï¼ˆè‹¥ reset å‰‡ç„¡ previous_idï¼‰
                model_used="o3-mini"
                response = client_ai.responses.create(
                    model=model_used,
                    input=input_prompt,
                    previous_response_id=state["last_response_id"],
                    store=True
                )

                reply = response.output_text
                state["last_response_id"] = response.id
                save_user_memory(user_id, state)

                await message.reply(reply)
                count = record_usage("æ¨ç†")
                await message.reply(f"ğŸ“Š ä»Šå¤©æ‰€æœ‰äººç¸½å…±ä½¿ç”¨ã€Œæ¨ç†ã€åŠŸèƒ½ {count} æ¬¡"+f"æœ¬æ¬¡ä½¿ç”¨çš„æ¨¡å‹ï¼š{model_used}")

            except Exception as e:
                await message.reply(f"âŒ AI äº’å‹•æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            finally:
                await thinking_message.delete()

        # --- åŠŸèƒ½ 2ï¼šå•ç­”ï¼ˆå«åœ–ç‰‡èˆ‡ PDFï¼‰ ---
        elif cmd.startswith("å• "):
            prompt = cmd[2:].strip()
            thinking_message = await message.reply("ğŸ§  Thinking...")

            try:
                user_id = f"{message.guild.id}-{message.author.id}" if message.guild else f"dm-{message.author.id}"
                state = load_user_memory(user_id)

                if "thread_count" not in state:
                    state["thread_count"] = 0
                state["thread_count"] += 1

                # âœ… æ¯ç¬¬ 10 è¼ªè§¸ç™¼æ‘˜è¦
                if state["thread_count"] >= 10 and state["last_response_id"]:
                    response = client_ai.responses.create(
                        model="gpt-4o",
                        previous_response_id=state["last_response_id"],
                        input=[{
                            "role": "user",
                            "content": (
                                "è«‹æ ¹æ“šæ•´æ®µå°è©±ï¼Œæ¿ƒç¸®ç‚ºä¸€æ®µå¹«åŠ© AI å»¶çºŒå°è©±çš„è¨˜æ†¶æ‘˜è¦ï¼Œ"
                                "æ‘˜è¦ä¸­æ‡‰åŒ…å«ä½¿ç”¨è€…çš„ä¸»è¦ç›®æ¨™ã€å•é¡Œé¡å‹ã€èªæ°£ç‰¹å¾µèˆ‡é‡è¦èƒŒæ™¯çŸ¥è­˜ï¼Œ"
                                "è®“ AI èƒ½ä»¥æ­¤ç‚ºåŸºç¤ç¹¼çºŒèˆ‡ä½¿ç”¨è€…æºé€šã€‚"
                            )
                        }],
                        store=False
                    )
                    state["summary"] = response.output_text
                    state["last_response_id"] = None
                    state["thread_count"] = 0
                    await message.channel.send("ğŸ“ å°è©±å·²é” 10 è¼ªï¼Œå·²è‡ªå‹•ç¸½çµä¸¦é‡æ–°é–‹å§‹ã€‚")

                # âœ… æº–å‚™ input_prompt
                input_prompt = []
                if state["summary"]:
                    input_prompt.append({
                        "role": "system",
                        "content": f"é€™æ˜¯å‰æ®µæ‘˜è¦ï¼š{state['summary']}"
                    })
                multimodal = [{"type": "input_text", "text": prompt}]

                for attachment in message.attachments[:3]:
                    if attachment.content_type and attachment.content_type.startswith("image/"):
                        image_url = attachment.proxy_url  # ä½¿ç”¨ proxy_url æ›¿ä»£ attachment.url
                        multimodal.append({
                            "type": "input_image",
                            "image_url": image_url,
                            "detail": "auto"
                        })

                for attachment in message.attachments:
                    if attachment.filename.endswith(".pdf") and attachment.size < 30 * 1024 * 1024:
                        pdf_bytes = await attachment.read()
                        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
                        pdf_text = ""
                        for page_num in range(min(5, len(doc))):
                            page = doc.load_page(page_num)
                            pdf_text += page.get_text()

                        multimodal.append({
                            "type": "input_text",
                            "text": f"[å‰5é PDFå…§å®¹æ‘˜è¦é–‹å§‹]\n{pdf_text[:3000]}\n[æ‘˜è¦çµæŸ]"
                        })

                        encoded_pdf = base64.b64encode(pdf_bytes).decode("utf-8")
                        multimodal.append({
                            "type": "input_file",
                            "filename": attachment.filename,
                            "file_data": f"data:application/pdf;base64,{encoded_pdf}",
                            "file_url": attachment.proxy_url
                        })

                input_prompt.append({
                    "role": "user",
                    "content": multimodal
                })
                current_count = record_usage("å•")  # é€™è£¡åŒæ™‚ä¹Ÿæœƒç´¯åŠ ä¸€æ¬¡ä½¿ç”¨æ¬¡æ•¸
                if current_count <= 50:
                    model_used = "gpt-4o"
                else:
                    model_used = "gpt-4o-mini"

                response = client_ai.responses.create(
                    model=model_used,  # ä½¿ç”¨å‹•æ…‹æ±ºå®šçš„æ¨¡å‹
                    input=input_prompt,
                    previous_response_id=state["last_response_id"],
                    store=True
                )

                reply = response.output_text
                state["last_response_id"] = response.id
                save_user_memory(user_id, state)

                await message.reply(reply)
                count = record_usage("å•")
                await message.reply(f"ğŸ“Š ä»Šå¤©æ‰€æœ‰äººç¸½å…±ä½¿ç”¨ã€Œå•ã€åŠŸèƒ½ {count} æ¬¡"+f"æœ¬æ¬¡ä½¿ç”¨çš„æ¨¡å‹ï¼š{model_used}")

            except Exception as e:
                await message.reply(f"âŒ AI äº’å‹•æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            finally:
                await thinking_message.delete()

        # --- åŠŸèƒ½ 3ï¼šå…§å®¹æ•´ç†æ‘˜è¦ ---
        elif cmd.startswith("æ•´ç† "):
            parts = cmd.split()
            if len(parts) != 3 or not parts[1].isdigit() or not parts[2].isdigit():
                await message.reply("âš ï¸ ä½¿ç”¨æ–¹æ³•ï¼š`!æ•´ç† <ä¾†æºé »é“/è¨è«–ä¸²ID> <æ‘˜è¦è¦é€åˆ°çš„é »é“ID>`")
                continue

            source_id = int(parts[1])
            summary_channel_id = int(parts[2])
            await message.reply(f"ğŸ” æ­£åœ¨æœå°‹ä¾†æº ID `{source_id}` èˆ‡ç›®æ¨™é »é“ ID `{summary_channel_id}`...")

            source_channel = client.get_channel(source_id)
            summary_channel = client.get_channel(summary_channel_id)
            if not isinstance(source_channel, (discord.Thread, discord.TextChannel)) or not isinstance(summary_channel, discord.TextChannel):
                await message.reply("âš ï¸ æ‰¾ä¸åˆ°ä¾†æºæˆ–ç›®æ¨™é »é“ï¼Œè«‹ç¢ºèª bot æ¬Šé™èˆ‡ ID æ˜¯å¦æ­£ç¢ºã€‚")
                continue

            await message.reply("ğŸ§¹ æ­£åœ¨æ•´ç†å…§å®¹ï¼Œè«‹ç¨å¾Œ...")
            try:
                messages_history = [msg async for msg in source_channel.history(limit=50)]
                conversation = "\n".join(f"{msg.author.display_name}: {msg.content}" for msg in reversed(messages_history))
                source_type = f"è¨è«–ä¸²ï¼š{source_channel.name}" if isinstance(source_channel, discord.Thread) else f"é »é“ï¼š{source_channel.name}"
                model_used="gpt-4o-mini"
                response = client_ai.responses.create(
                    model=model_used,
                    input=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æ“…é•·å…§å®¹æ‘˜è¦çš„åŠ©ç†ï¼Œè«‹æ•´ç†ä»¥ä¸‹ Discord è¨Šæ¯æˆç‚ºæ¢ç†æ¸…æ¥šã€æ˜“è®€çš„æ‘˜è¦ã€‚"},
                        {"role": "user", "content": conversation}
                    ]
                )

                summary = response.output_text
                embed = discord.Embed(title=f"å…§å®¹æ‘˜è¦ï¼š{source_type}", description=summary, color=discord.Color.blue())
                embed.set_footer(text=f"ä¾†æºID: {source_id}")
                await summary_channel.send(embed=embed)
                await message.reply("âœ… å…§å®¹æ‘˜è¦å·²ç¶“ç™¼é€ï¼")

                count = record_usage("æ•´ç†")
                await message.reply(f"ğŸ“Š ä»Šå¤©æ‰€æœ‰äººç¸½å…±ä½¿ç”¨ã€Œæ•´ç†ã€åŠŸèƒ½ {count} æ¬¡"+f"æœ¬æ¬¡ä½¿ç”¨çš„æ¨¡å‹ï¼š{model_used}")
            except Exception as e:
                await message.reply(f"âŒ æ‘˜è¦æ•´ç†æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        # --- åŠŸèƒ½ 4ï¼šæœå°‹æŸ¥è©¢ ---
        elif cmd.startswith("æœå°‹ "):
            if is_usage_exceeded("æœå°‹", limit=20):
                await message.reply("âš ï¸ ä»Šå¤©æœå°‹æ¬¡æ•¸å·²é”ä¸Šé™ï¼ˆ20æ¬¡ï¼‰ï¼Œè«‹æ˜å¤©å†è©¦ã€‚")
                continue
            query = cmd[2:].strip()

            thinking_message = await message.reply("ğŸ” æœå°‹ä¸­...")
            try:
                model_used="sonar"
                payload = {
                    "model": model_used,
                    "messages": [
                        {
                            "role": "system",
                            "content": "ä½ å…·å‚™è±å¯Œæƒ…ç·’èˆ‡æºé€šèƒ½åŠ›ï¼Œèƒ½ä¾å°è©±å…§å®¹çµ¦äºˆæœ‰è¶£å›æ‡‰ï¼Œä¸¦ä»¥å°ˆæ¥­å­¸ç§‘åˆ†é¡ç°¡æ˜è§£ç­”å•é¡Œã€‚ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œå›ç­”ç²¾ç°¡æœ‰é‡é»ï¼Œæ§åˆ¶åœ¨200å­—å…§ï¼Œé©åº¦æä¾›çœŸå¯¦å°ºåº¦çš„åˆ†æï¼Œä¸¦é¡¯ç¤º input/output token ä½¿ç”¨é‡ã€‚"
                        },
                        {"role": "user", "content": query}
                    ],
                    "max_tokens": 1000,
                    "temperature": 1.2,
                    "top_p": 0.9,
                    "top_k": 0,
                    "stream": False,
                    "presence_penalty": 0,
                    "frequency_penalty": 1,
                    " response_format": {},
                    "web_search_options": {"search_context_size": "low"}
                }
                headers = {
                    "Authorization": f"Bearer {PERPLEXITY_API_KEY}",
                    "Content-Type": "application/json"
                }
                response = requests.post("https://api.perplexity.ai/chat/completions", json=payload, headers=headers)
                if response.status_code == 200:
                    data = response.json()
                    reply = data["choices"][0]["message"]["content"]
                    await message.reply(reply)

                    count = record_usage("æœå°‹")
                    await message.reply(f"ğŸ“Š ä»Šå¤©æ‰€æœ‰äººç¸½å…±ä½¿ç”¨ã€Œæœå°‹ã€åŠŸèƒ½ {count} æ¬¡"+f"æœ¬æ¬¡ä½¿ç”¨çš„æ¨¡å‹ï¼š{model_used}")
                else:
                    await message.reply(f"âŒ æœå°‹æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼ŒHTTP ç‹€æ…‹ç¢¼ï¼š{response.status_code}")
            except Exception as e:
                await message.reply(f"âŒ æœå°‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            finally:
                await thinking_message.delete()

        elif cmd.startswith("é‡ç½®è¨˜æ†¶"):
            user_id = f"{message.guild.id}-{message.author.id}" if message.guild else f"dm-{message.author.id}"
            await message.reply("âš ï¸ ä½ ç¢ºå®šè¦é‡ç½®è¨˜æ†¶å—ï¼Ÿå»ºè­°åˆ©ç”¨ã€é¡¯ç¤ºè¨˜æ†¶ã€‘æŒ‡ä»¤å‚™ä»½ç›®å‰è¨˜æ†¶ã€‚è‹¥è¦é‡ç½®ï¼Œè«‹å›è¦†ã€Œç¢ºå®šé‡ç½®ã€ï¼›è‹¥è¦å–æ¶ˆï¼Œè«‹å›è¦†ã€Œå–æ¶ˆé‡ç½®ã€ã€‚")
            pending_reset_confirmations[user_id] = True

        elif cmd.startswith("ç¢ºå®šé‡ç½®"):
            user_id = f"{message.guild.id}-{message.author.id}" if message.guild else f"dm-{message.author.id}"
            if pending_reset_confirmations.get(user_id):
                pending_reset_confirmations.pop(user_id)
                state = {
                    "summary": "",
                    "history": [],
                    "token_accum": 0,
                    "last_response_id": None,
                    "thread_count": 0
                }
                save_user_memory(user_id, state)
                await message.reply("âœ… è¨˜æ†¶å·²é‡ç½®")
            else:
                await message.reply("âš ï¸ æ²’æœ‰å¾…ç¢ºèªçš„é‡ç½®è«‹æ±‚ã€‚")

        elif cmd.startswith("å–æ¶ˆé‡ç½®"):
            user_id = f"{message.guild.id}-{message.author.id}" if message.guild else f"dm-{message.author.id}"
            if pending_reset_confirmations.get(user_id):
                pending_reset_confirmations.pop(user_id)
                await message.reply("å·²å–æ¶ˆè¨˜æ†¶é‡ç½®ã€‚")
            else:
                await message.reply("âš ï¸ æ²’æœ‰å¾…ç¢ºèªçš„é‡ç½®è«‹æ±‚ã€‚")
        elif cmd.startswith("é¡¯ç¤ºè¨˜æ†¶"):
            user_id = f"{message.guild.id}-{message.author.id}" if message.guild else f"dm-{message.author.id}"
            state = load_user_memory(user_id)
            summary = state.get("summary", "")
            if summary:
                await message.reply(f"ğŸ“– ç›®å‰é•·æœŸè¨˜æ†¶æ‘˜è¦ï¼š\n{summary}")
            else:
                await message.reply("ç›®å‰å°šç„¡é•·æœŸè¨˜æ†¶æ‘˜è¦ã€‚")


                
# ===== 7. å•Ÿå‹• Bot =====
client.run(DISCORD_TOKEN)
