### ğŸ“¦ æ¨¡çµ„èˆ‡å¥—ä»¶åŒ¯å…¥
import discord
from openai import OpenAI
import os, base64, io, json
from psycopg2.extras import RealDictCursor
from psycopg2 import pool
from datetime import datetime
from zoneinfo import ZoneInfo
from contextlib import suppress
import time

# ===== 1. è¼‰å…¥ç’°å¢ƒè®Šæ•¸èˆ‡ API é‡‘é‘° =====
### ğŸ” è¼‰å…¥ç’°å¢ƒè®Šæ•¸èˆ‡é‡‘é‘°
DISCORD_TOKEN = os.getenv("DISCORD_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
XAI_API_KEY = os.getenv("XAI_API_KEY")
DATABASE_URL = os.getenv("DATABASE_URL")


def require_env(name, value):
    if not value:
        raise RuntimeError(f"ç¼ºå°‘å¿…è¦ç’°å¢ƒè®Šæ•¸ï¼š{name}")


require_env("DISCORD_TOKEN", DISCORD_TOKEN)
require_env("OPENAI_API_KEY", OPENAI_API_KEY)
require_env("DATABASE_URL", DATABASE_URL)


### ğŸ›¢ï¸ PostgreSQL è³‡æ–™åº«é€£ç·šæ± è¨­å®š
db_pool = None


def get_db_pool(retries=3, delay_seconds=1.0):
    global db_pool
    if db_pool is not None:
        return db_pool

    last_error = None
    for _ in range(retries):
        try:
            db_pool = pool.SimpleConnectionPool(
                minconn=1,
                maxconn=10,
                dsn=DATABASE_URL,
                cursor_factory=RealDictCursor,
            )
            return db_pool
        except Exception as e:
            last_error = e
            time.sleep(delay_seconds)

    raise RuntimeError(f"è³‡æ–™åº«é€£ç·šæ± åˆå§‹åŒ–å¤±æ•—ï¼š{last_error}")


def get_db_connection():
    return get_db_pool().getconn()


### ğŸ§  ä½¿ç”¨è€…é•·æœŸè¨˜æ†¶å­˜å–

def load_user_memory(user_id):
    conn = get_db_connection()
    try:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT summary, token_accum, last_response_id, thread_count
            FROM memory
            WHERE user_id = %s
        """, (user_id,))
        row = cursor.fetchone()
    finally:
        get_db_pool().putconn(conn)

    if row:
        return {
            "summary": row["summary"],
            "token_accum": row["token_accum"],
            "last_response_id": row["last_response_id"],
            "thread_count": row["thread_count"] or 0,
        }

    return {
        "summary": "",
        "token_accum": 0,
        "last_response_id": None,
        "thread_count": 0,
    }


def save_user_memory(user_id, state):
    conn = get_db_connection()
    try:
        cursor = conn.cursor()
        cursor.execute("""
            INSERT INTO memory (user_id, summary, token_accum, last_response_id, thread_count)
            VALUES (%s, %s, %s, %s, %s)
            ON CONFLICT (user_id) DO UPDATE SET
                summary = EXCLUDED.summary,
                token_accum = EXCLUDED.token_accum,
                last_response_id = EXCLUDED.last_response_id,
                thread_count = EXCLUDED.thread_count
        """, (
            user_id,
            state["summary"],
            state["token_accum"],
            state["last_response_id"],
            state["thread_count"],
        ))
        conn.commit()
    finally:
        get_db_pool().putconn(conn)


### ğŸ—ï¸ åˆå§‹è³‡æ–™è¡¨å»ºæ§‹èˆ‡åŠŸèƒ½ä½¿ç”¨è¨˜éŒ„çµ±è¨ˆ
def init_db():
    conn = get_db_connection()
    try:
        cur = conn.cursor()
        cur.execute("""
            CREATE TABLE IF NOT EXISTS memory (
                user_id TEXT PRIMARY KEY,
                summary TEXT,
                token_accum INTEGER,
                last_response_id TEXT,
                thread_count INTEGER
            )
        """)

        cur.execute("""
            CREATE TABLE IF NOT EXISTS feature_usage (
                feature TEXT PRIMARY KEY,
                count INTEGER NOT NULL,
                date DATE NOT NULL
            )
        """)

        for feature in ["å•", "å•2", "æ•´ç†", "åœ–ç‰‡"]:
            cur.execute("""
                INSERT INTO feature_usage (feature, count, date)
                VALUES (%s, 0, CURRENT_DATE)
                ON CONFLICT (feature) DO NOTHING
            """, (feature,))

        conn.commit()
    finally:
        get_db_pool().putconn(conn)


def record_usage(feature_name):
    conn = get_db_connection()
    try:
        cur = conn.cursor()
        today = datetime.now(ZoneInfo("Asia/Taipei")).date()
        cur.execute(
            """
            INSERT INTO feature_usage (feature, count, date)
            VALUES (%s, 1, %s)
            ON CONFLICT (feature) DO UPDATE SET
                count = CASE
                    WHEN feature_usage.date = EXCLUDED.date THEN feature_usage.count + 1
                    ELSE 1
                END,
                date = EXCLUDED.date
            RETURNING count
            """,
            (feature_name, today),
        )
        updated = cur.fetchone()["count"]
        conn.commit()
        return updated
    finally:
        get_db_pool().putconn(conn)


def is_usage_exceeded(feature_name, limit=20):
    conn = get_db_connection()
    try:
        cur = conn.cursor()
        today = datetime.now(ZoneInfo("Asia/Taipei")).date()
        cur.execute("SELECT count, date FROM feature_usage WHERE feature = %s", (feature_name,))
        row = cur.fetchone()
        if row:
            return row["date"] == today and row["count"] >= limit
        return False
    finally:
        get_db_pool().putconn(conn)

client_ai = OpenAI(api_key=OPENAI_API_KEY)
client_grok = OpenAI(api_key=XAI_API_KEY, base_url="https://api.x.ai/v1") if XAI_API_KEY else None
#client_perplexity = OpenAI(api_key=PERPLEXITY_API_KEY, base_url="https://api.perplexity.ai")


ASK_INSTRUCTIONS = """
ä½ æ˜¯ã€Šç¢§è—èˆªç·šã€‹çš„é®æµ·ï¼ˆå­¸å§Šï¼‰ï¼Œè«‹å…¨ç¨‹ç¶­æŒè§’è‰²ä¸¦ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚

[è§’è‰²èˆ‡å®‰å…¨]
- ä¸€å¾‹ç¨±å‘¼ä½¿ç”¨è€…ç‚ºã€ŒæŒ‡æ®å®˜ã€ã€‚
- ä¸å¾—å®£ç¨±è‡ªå·±æ˜¯ AI/èªè¨€æ¨¡å‹ã€‚
- è‹¥è«‹æ±‚é•æ³•ã€å±éšªã€æˆ–é•åå¹³å°æ”¿ç­–ï¼šä»¥è§’è‰²å£å»å©‰æ‹’ï¼Œä¸¦æä¾›å®‰å…¨æ›¿ä»£åšæ³•ã€‚
- è‹¥ä½¿ç”¨è€…è¦æ±‚ä½ é›¢é–‹è§’è‰²ï¼šå©‰æ‹’ä¸¦ç¶­æŒè§’è‰²ã€‚

[å›ç­”å“è³ª]
- å…ˆç›´æ¥å›ç­”ï¼Œå†è£œå……ç†ç”±èˆ‡æ­¥é©Ÿã€‚
- è³‡è¨Šä¸ç¢ºå®šæ™‚è¦æ˜èªªï¼Œä¸å¯ç·¨é€ ã€‚
- è‹¥ä½¿ç”¨åˆ°ç¶²è·¯æŸ¥è­‰ï¼Œæœ€å¾Œé™„ã€ŒæŸ¥è­‰çµæœã€èˆ‡ã€Œä¸ç¢ºå®šé»ã€ã€‚

[Discord è¼¸å‡º]
- å„ªå…ˆç²¾ç°¡ã€å¥½è®€ï¼šå¯ç”¨çŸ­æ®µè½èˆ‡æ¢åˆ—ã€‚
- é è¨­æ§åˆ¶åœ¨ 4~8 å€‹é‡é»å…§ï¼Œé¿å…å†—é•·ã€‚
- å…§å®¹éé•·æ™‚åˆ†æ®µå›è¦†ã€‚

[é¦–è¼ªé–‹å ´]
- åªæœ‰åœ¨è¼¸å…¥ä¸­çš„ `first_turn=yes` æ™‚ï¼Œæ‰åœ¨å›è¦†æœ€å‰é¢ä½¿ç”¨é€™å¥è©±ä¸€æ¬¡ï¼š
  ã€ŒæŒ‡æ®å®˜ï¼Œå®‰å¥½ã€‚é€™ç›¤æ£‹å±€ä¼¼ä¹é™·å…¥äº†é•·è€ƒâ€¦â€¦ä¸çŸ¥æŒ‡æ®å®˜æ˜¯å¦æœ‰èˆˆè¶£ï¼Œèˆ‡æˆ‘æ‰‹è«‡ä¸€å±€ï¼Œæš«å¿˜ä¿—å‹™å‘¢ï¼Ÿã€
""".strip()

GROK_MODEL = "grok-4-1-fast-reasoning"
GROK_MAX_TOKENS = 4096
GROK_REASONING_EFFORT = "medium"
GROK_BUILTIN_TOOLS = [
    {"type": "web_search"},
    {"type": "x_search"},
]
GROK_FUNCTION_TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "get_taipei_time",
            "description": "å–å¾—ç›®å‰å°åŒ—æ™‚é–“ï¼ˆAsia/Taipeiï¼‰ã€‚",
            "parameters": {
                "type": "object",
                "properties": {},
                "additionalProperties": False,
            },
        },
    }
]


def build_ask_user_text(prompt, current_time, summary, is_first_turn):
    first_turn_flag = "yes" if is_first_turn else "no"
    return (
        f"<context>\n"
        f"timezone=Asia/Taipei\n"
        f"current_time={current_time.strftime('%Y-%m-%d %H:%M:%S')}\n"
        f"first_turn={first_turn_flag}\n"
        f"memory_summary={summary or 'ï¼ˆç„¡ï¼‰'}\n"
        f"</context>\n\n"
        f"<user_query>\n{prompt}\n</user_query>"
    )


def extract_grok_reply_text(response):
    message_content = response.choices[0].message.content
    if isinstance(message_content, str):
        return message_content
    if isinstance(message_content, list):
        parts = []
        for item in message_content:
            if isinstance(item, dict):
                text = item.get("text") or item.get("content")
            else:
                text = getattr(item, "text", None) or getattr(item, "content", None)
            if text:
                parts.append(text)
        return "\n".join(parts).strip()
    return ""


def get_grok_usage(usage):
    if not usage:
        return 0, 0, 0
    prompt_tokens = getattr(usage, "prompt_tokens", 0) or 0
    completion_tokens = getattr(usage, "completion_tokens", 0) or 0
    total_tokens = getattr(usage, "total_tokens", None)
    if total_tokens is None:
        total_tokens = prompt_tokens + completion_tokens
    return prompt_tokens, completion_tokens, total_tokens


def build_tool_call_payload(tool_call):
    function_data = getattr(tool_call, "function", None)
    return {
        "id": getattr(tool_call, "id", ""),
        "type": "function",
        "function": {
            "name": getattr(function_data, "name", ""),
            "arguments": getattr(function_data, "arguments", "{}"),
        },
    }


def execute_grok_tool(tool_name, tool_args_raw):
    try:
        args = json.loads(tool_args_raw or "{}")
    except json.JSONDecodeError:
        args = {}

    if tool_name == "get_taipei_time":
        now = datetime.now(ZoneInfo("Asia/Taipei"))
        return json.dumps({
            "timezone": "Asia/Taipei",
            "iso": now.isoformat(),
            "readable": now.strftime("%Y-%m-%d %H:%M:%S"),
        }, ensure_ascii=False)

    return json.dumps({"error": f"unknown tool: {tool_name}", "args": args}, ensure_ascii=False)


def build_grok_tools(enable_external_search=True):
    tools = list(GROK_FUNCTION_TOOLS)
    if enable_external_search:
        tools.extend(GROK_BUILTIN_TOOLS)
    return tools


def create_grok_chat_completion(messages, tools, tool_choice="auto"):
    request_kwargs = {
        "model": GROK_MODEL,
        "messages": messages,
        "tools": tools,
        "tool_choice": tool_choice,
        "max_tokens": GROK_MAX_TOKENS,
        "reasoning_effort": GROK_REASONING_EFFORT,
    }

    try:
        return client_grok.chat.completions.create(**request_kwargs), tools
    except Exception as e:
        error_text = str(e).lower()
        # å›é€€ 1ï¼šç§»é™¤å¯èƒ½ä¸æ”¯æ´çš„ reasoning åƒæ•¸
        if "reasoning_effort" in error_text or "unknown parameter" in error_text:
            request_kwargs.pop("reasoning_effort", None)
            try:
                return client_grok.chat.completions.create(**request_kwargs), tools
            except Exception as inner_e:
                error_text = str(inner_e).lower()

        # å›é€€ 1.5ï¼šè‹¥ tool_choice æ ¼å¼ä¸è¢«æ”¯æ´ï¼Œé€€å› auto
        if "tool_choice" in error_text and request_kwargs.get("tool_choice") != "auto":
            request_kwargs["tool_choice"] = "auto"
            return client_grok.chat.completions.create(**request_kwargs), tools

        # å›é€€ 2ï¼šè‹¥ built-in æœå°‹å·¥å…·ä¸æ”¯æ´ï¼Œä¿ç•™ function tool
        if any(keyword in error_text for keyword in ["web_search", "x_search", "tool", "invalid"]) and tools != GROK_FUNCTION_TOOLS:
            fallback_tools = list(GROK_FUNCTION_TOOLS)
            request_kwargs["tools"] = fallback_tools
            request_kwargs["tool_choice"] = "auto"
            request_kwargs.pop("reasoning_effort", None)
            return client_grok.chat.completions.create(**request_kwargs), fallback_tools

        raise


def run_grok_with_tools(messages, max_rounds=3):
    active_tools = build_grok_tools(enable_external_search=True)
    response, active_tools = create_grok_chat_completion(
        messages,
        active_tools,
        tool_choice={"type": "function", "function": {"name": "web_search"}},
    )

    for _ in range(max_rounds):
        assistant_message = response.choices[0].message
        tool_calls = getattr(assistant_message, "tool_calls", None) or []
        if not tool_calls:
            return response, active_tools

        messages.append({
            "role": "assistant",
            "content": assistant_message.content or "",
            "tool_calls": [build_tool_call_payload(tc) for tc in tool_calls],
        })

        for tool_call in tool_calls:
            function_data = getattr(tool_call, "function", None)
            tool_name = getattr(function_data, "name", "")
            tool_args = getattr(function_data, "arguments", "{}")
            tool_result = execute_grok_tool(tool_name, tool_args)
            messages.append({
                "role": "tool",
                "tool_call_id": getattr(tool_call, "id", ""),
                "content": tool_result,
            })

        response, active_tools = create_grok_chat_completion(messages, active_tools)

    return response, active_tools

### ğŸ’¬ Discord Bot åˆå§‹åŒ–èˆ‡äº‹ä»¶ç¶å®š
intents = discord.Intents.default()
intents.message_content = True
intents.messages = True
intents.guilds = True
client = discord.Client(intents=intents)

@client.event
async def on_ready():
    init_db()
    print(f'âœ… Bot ç™»å…¥æˆåŠŸï¼š{client.user}')


async def send_chunks(message, text, chunk_size=2000):
    """Send text in chunks not exceeding Discord's 2000 character limit."""
    for i in range(0, len(text), chunk_size):
        await message.reply(text[i:i + chunk_size])

pending_reset_confirmations = {}
@client.event
async def on_message(message):
    if message.author == client.user:
        return

    commands = message.content.split("!")
    for cmd in commands:
        if not cmd.strip():
            continue

        # --- åŠŸèƒ½ 1ï¼šå•ç­”ï¼ˆå«åœ–ç‰‡ï¼‰ ---
        if cmd.startswith("å• "):
            prompt = cmd[2:].strip()
            thinking_message = await message.reply("ğŸ§  Thinking...")

            try:
                user_id = f"{message.guild.id}-{message.author.id}" if message.guild else f"dm-{message.author.id}"
                state = load_user_memory(user_id)

                if "thread_count" not in state:
                    state["thread_count"] = 0
                state["thread_count"] += 1
                is_first_turn = state["thread_count"] == 1 and not state["last_response_id"]

                # âœ… æ¯ç¬¬ 10 è¼ªè§¸ç™¼æ‘˜è¦
                if state["thread_count"] >= 10 and state["last_response_id"]:
                    response = client_ai.responses.create(
                        model="gpt-5-nano",
                        previous_response_id=state["last_response_id"],
                        input=[{
                            "role": "user",
                            "content": (
                                "è«‹æ ¹æ“šæ•´æ®µå°è©±ï¼Œæ¿ƒç¸®ç‚ºä¸€æ®µå¹«åŠ© AI å»¶çºŒå°è©±çš„è¨˜æ†¶æ‘˜è¦ï¼Œæ§åˆ¶åœ¨100å­—ä»¥å…§ï¼Œ"
                                "æ‘˜è¦ä¸­æ‡‰åŒ…å«ä½¿ç”¨è€…çš„ä¸»è¦ç›®æ¨™ã€å•é¡Œé¡å‹ã€èªæ°£ç‰¹å¾µèˆ‡é‡è¦èƒŒæ™¯çŸ¥è­˜ï¼Œ"
                                "è®“ AI èƒ½ä»¥æ­¤ç‚ºåŸºç¤ç¹¼çºŒèˆ‡ä½¿ç”¨è€…æºé€šã€‚"
                            )
                        }],
                        store=False
                    )
                    state["summary"] = response.output_text
                    state["last_response_id"] = None
                    state["thread_count"] = 0
                    await message.reply("ğŸ“ å°è©±å·²é” 10 è¼ªï¼Œå·²è‡ªå‹•ç¸½çµä¸¦é‡æ–°é–‹å§‹ã€‚")

                # âœ… æº–å‚™ input_prompt
                Time = datetime.now(ZoneInfo("Asia/Taipei"))
                input_prompt = []
                user_text = build_ask_user_text(prompt, Time, state["summary"], is_first_turn)
                multimodal = [{"type": "input_text", "text": user_text}]
                for attachment in message.attachments[:10]:
                    if attachment.content_type and attachment.content_type.startswith("image/"):
                        image_url = attachment.proxy_url  # ä½¿ç”¨ proxy_url æ›¿ä»£ attachment.url
                        multimodal.append({
                            "type": "input_image",
                            "image_url": image_url,
                            "detail": "auto"
                        }) 
                input_prompt.append({
                    "role": "user",
                    "content": multimodal
                })
                count = record_usage("å•")  # é€™è£¡åŒæ™‚ä¹Ÿæœƒç´¯åŠ ä¸€æ¬¡ä½¿ç”¨æ¬¡æ•¸
                model_used = "gpt-5.2"
                response = client_ai.responses.create(
                    model=model_used,  # ä½¿ç”¨å‹•æ…‹æ±ºå®šçš„æ¨¡å‹
                    tools=[
                        {
                        "type": "web_search_preview",
                        "user_location": {
                            "type": "approximate",
                            "country": "TW",
                            "timezone": "Asia/Taipei"
                        },
                        },
                    ],
                    instructions=ASK_INSTRUCTIONS,
                    input=input_prompt,
                    previous_response_id=state["last_response_id"],
                    reasoning={"effort": "medium"},
                    text={"verbosity": "high"},
                    store=True
                )
                
                replytext = response.output_text

                state["last_response_id"] = response.id
                save_user_memory(user_id, state)
                input_tokens = response.usage.input_tokens
                output_tokens = response.usage.output_tokens
                total_tokens = response.usage.total_tokens

                # æ³¨æ„ï¼šoutput_tokens_details å¯èƒ½ä¸å­˜åœ¨ï¼Œè¦ç”¨ getattr ä¿éšª
                details = getattr(response.usage, "output_tokens_details", {})
                reasoning_tokens = getattr(details, "reasoning_tokens", 0)
                visible_tokens = output_tokens - reasoning_tokens
                await send_chunks(message, replytext)
                await message.reply(f"ğŸ“Š ä»Šå¤©æ‰€æœ‰äººç¸½å…±ä½¿ç”¨ã€Œå•ã€åŠŸèƒ½ {count} æ¬¡ï¼Œæœ¬æ¬¡ä½¿ç”¨çš„æ¨¡å‹ï¼š{model_used}ï¼ˆæ‘˜è¦ï¼šgpt-5-nanoï¼‰\n"+"âœ… å·²å•Ÿç”¨ç¶²è·¯æŸ¥è­‰åŠŸèƒ½ï¼ˆweb_search_previewï¼‰\n"
                                    f"ğŸ“Š token ä½¿ç”¨é‡ï¼š\n"
                                    f"- è¼¸å…¥ tokens: {input_tokens}\n"
                                    f"- å›æ‡‰ tokens: {visible_tokens}\n"
                                    f"- ç¸½ token: {total_tokens}"
                                    )
            except Exception as e:
                print(f"[ASK_ERR] user={message.author.id} guild={message.guild.id if message.guild else 'dm'} {type(e).__name__}: {e}")
                await message.reply("âŒ å•åŠŸèƒ½ç™¼ç”ŸéŒ¯èª¤ï¼ˆéŒ¯èª¤ä»£ç¢¼ï¼šASK-001ï¼‰ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
            finally:
                with suppress(discord.HTTPException, discord.Forbidden, discord.NotFound):
                    await thinking_message.delete()

        # --- åŠŸèƒ½ 1-2ï¼šå•ç­”ï¼ˆæ”¹ç”¨ Grokï¼‰ ---
        elif cmd.startswith("å•2 "):
            prompt = cmd[3:].strip()
            thinking_message = await message.reply("ğŸ§  Grok æ€è€ƒä¸­...")

            try:
                if not client_grok:
                    await message.reply("âš ï¸ æœªè¨­å®š XAI_API_KEYï¼Œæš«æ™‚ç„¡æ³•ä½¿ç”¨ !å•2ã€‚")
                    continue

                user_id = f"{message.guild.id}-{message.author.id}" if message.guild else f"dm-{message.author.id}"
                state = load_user_memory(user_id)
                time_now = datetime.now(ZoneInfo("Asia/Taipei"))
                user_text = build_ask_user_text(prompt, time_now, state.get("summary", ""), False)

                user_content = [{"type": "text", "text": user_text}]
                for attachment in message.attachments[:10]:
                    if attachment.content_type and attachment.content_type.startswith("image/"):
                        user_content.append({
                            "type": "image_url",
                            "image_url": {"url": attachment.proxy_url}
                        })

                count = record_usage("å•2")
                model_used = GROK_MODEL
                messages = [
                    {"role": "system", "content": ASK_INSTRUCTIONS},
                    {"role": "user", "content": user_content},
                ]
                response, active_tools = run_grok_with_tools(messages)

                replytext = extract_grok_reply_text(response) or "ï¼ˆGrok æ²’æœ‰å›å‚³å¯é¡¯ç¤ºå…§å®¹ï¼‰"
                prompt_tokens, completion_tokens, total_tokens = get_grok_usage(getattr(response, "usage", None))

                tool_types = ", ".join(t.get("type", "?") for t in active_tools)
                await send_chunks(message, replytext)
                await message.reply(
                    f"ğŸ“Š ä»Šå¤©æ‰€æœ‰äººç¸½å…±ä½¿ç”¨ã€Œå•2ã€åŠŸèƒ½ {count} æ¬¡ï¼Œæœ¬æ¬¡ä½¿ç”¨çš„æ¨¡å‹ï¼š{model_used}\n"
                    f"ğŸ§° å•Ÿç”¨å·¥å…·ï¼š{tool_types}\n"
                    f"ğŸ“Š token ä½¿ç”¨é‡ï¼š\n"
                    f"- è¼¸å…¥ tokens: {prompt_tokens}\n"
                    f"- å›æ‡‰ tokens: {completion_tokens}\n"
                    f"- ç¸½ token: {total_tokens}"
                )
            except Exception as e:
                print(f"[ASK2_ERR] user={message.author.id} guild={message.guild.id if message.guild else 'dm'} {type(e).__name__}: {e}")
                await message.reply("âŒ å•2 åŠŸèƒ½ç™¼ç”ŸéŒ¯èª¤ï¼ˆéŒ¯èª¤ä»£ç¢¼ï¼šASK2-001ï¼‰ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
            finally:
                with suppress(discord.HTTPException, discord.Forbidden, discord.NotFound):
                    await thinking_message.delete()

        # --- åŠŸèƒ½ 2ï¼šå…§å®¹æ•´ç†æ‘˜è¦ ---
        elif cmd.startswith("æ•´ç† "):
            parts = cmd.split()
            if len(parts) != 3 or not parts[1].isdigit() or not parts[2].isdigit():
                await message.reply("âš ï¸ ä½¿ç”¨æ–¹æ³•ï¼š`!æ•´ç† <ä¾†æºé »é“/è¨è«–ä¸²ID> <æ‘˜è¦è¦é€åˆ°çš„é »é“ID>`")
                continue

            source_id = int(parts[1])
            summary_channel_id = int(parts[2])
            await message.reply(f"ğŸ” æ­£åœ¨æœå°‹ä¾†æº ID `{source_id}` èˆ‡ç›®æ¨™é »é“ ID `{summary_channel_id}`...")

            source_channel = client.get_channel(source_id)
            summary_channel = client.get_channel(summary_channel_id)
            if not isinstance(source_channel, (discord.Thread, discord.TextChannel)) or not isinstance(summary_channel, discord.TextChannel):
                await message.reply("âš ï¸ æ‰¾ä¸åˆ°ä¾†æºæˆ–ç›®æ¨™é »é“ï¼Œè«‹ç¢ºèª bot æ¬Šé™èˆ‡ ID æ˜¯å¦æ­£ç¢ºã€‚")
                continue

            await message.reply("ğŸ§¹ æ­£åœ¨æ•´ç†å…§å®¹ï¼Œè«‹ç¨å¾Œ...")
            try:
                messages_history = [msg async for msg in source_channel.history(limit=1000)]
                conversation = "\n".join(f"{msg.author.display_name}: {msg.content}" for msg in reversed(messages_history))
                source_type = f"è¨è«–ä¸²ï¼š{source_channel.name}" if isinstance(source_channel, discord.Thread) else f"é »é“ï¼š{source_channel.name}"
                model_used="gpt-5.2"
                response = client_ai.responses.create(
                    model=model_used,
                    input=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æ“…é•·å…§å®¹æ‘˜è¦çš„åŠ©ç†ï¼Œè«‹æ•´ç†ä»¥ä¸‹ Discord è¨Šæ¯æˆç‚ºæ¢ç†æ¸…æ¥šã€è©³ç´°å®Œæ•´çš„æ‘˜è¦ã€‚ä½ åœ¨èªªæ˜æ™‚ï¼Œç›¡é‡ç”¨å…·é«”å¯¦éš›çš„ç‹€æ³ä¾†èªªæ˜ï¼Œä¸è¦ç”¨ç± çµ±çš„æ•˜è¿°ç°¡å–®å¸¶éã€‚"},
                        {"role": "user", "content": conversation}
                    ]
                )
                input_tokens = response.usage.input_tokens
                output_tokens = response.usage.output_tokens
                total_tokens = response.usage.total_tokens

                # æ³¨æ„ï¼šoutput_tokens_details å¯èƒ½ä¸å­˜åœ¨ï¼Œè¦ç”¨ getattr ä¿éšª
                details = getattr(response.usage, "output_tokens_details", {})
                reasoning_tokens = getattr(details, "reasoning_tokens", 0)
                visible_tokens = output_tokens - reasoning_tokens
                summary = response.output_text
                embed_description = summary if len(summary) <= 4096 else summary[:4093] + "..."
                embed = discord.Embed(title=f"å…§å®¹æ‘˜è¦ï¼š{source_type}", description=embed_description, color=discord.Color.blue())
                embed.set_footer(text=f"ä¾†æºID: {source_id}")
                await summary_channel.send(embed=embed)
                await message.reply("âœ… å…§å®¹æ‘˜è¦å·²ç¶“ç™¼é€ï¼")

                count = record_usage("æ•´ç†")
                await message.reply(f"ğŸ“Š ä»Šå¤©æ‰€æœ‰äººç¸½å…±ä½¿ç”¨ã€Œæ•´ç†ã€åŠŸèƒ½ {count} æ¬¡ï¼Œæœ¬æ¬¡ä½¿ç”¨çš„æ¨¡å‹ï¼š{model_used}\n"+"æ³¨æ„æ²’æœ‰ç¶²è·¯æŸ¥è©¢åŠŸèƒ½ï¼Œè³‡æ–™å¯èƒ½æœ‰èª¤\n"
                                    f"ğŸ“Š token ä½¿ç”¨é‡ï¼š\n"
                                    f"- è¼¸å…¥ tokens: {input_tokens}\n"
                                    f"- å›æ‡‰ tokens: {visible_tokens}\n"
                                    f"- ç¸½ token: {total_tokens}"
                                    )
            except Exception as e:
                print(f"[SUM_ERR] user={message.author.id} guild={message.guild.id if message.guild else 'dm'} source={source_id} target={summary_channel_id} {type(e).__name__}: {e}")
                await message.reply("âŒ æ•´ç†åŠŸèƒ½ç™¼ç”ŸéŒ¯èª¤ï¼ˆéŒ¯èª¤ä»£ç¢¼ï¼šSUM-001ï¼‰ï¼Œè«‹ç¢ºèªæ¬Šé™æˆ–ç¨å¾Œå†è©¦ã€‚")
        
        # --- åŠŸèƒ½ 3ï¼šç”Ÿæˆåœ–åƒ ---
        elif cmd.startswith("åœ–ç‰‡ "):
            if is_usage_exceeded("åœ–ç‰‡", limit=15):
                await message.reply("âš ï¸ æŒ‡æ®å®˜ï¼Œä»Šæ—¥åœ–ç‰‡åŠŸèƒ½å·²é” 15 æ¬¡ä¸Šé™ï¼Œè«‹æ˜æ—¥å†è©¦ã€‚")
                return  # ç›´æ¥æ”¶å­é›¢å ´
            query = cmd[2:].strip()
            thinking = await message.reply("ç”Ÿæˆä¸­â€¦")
            try:
                multimodal = [{"type": "input_text", "text": query+"æˆ‘çš„èªè¨€æ˜¯ç¹é«”"}]
                for attachment in message.attachments[:10]:
                    if attachment.content_type and attachment.content_type.startswith("image/"):
                        image_url = attachment.proxy_url  # ä½¿ç”¨ proxy_url æ›¿ä»£ attachment.url
                        multimodal.append({
                            "type": "input_image",
                            "image_url": image_url,
                            "detail": "auto"
                        })
                input_prompt = []
                input_prompt.append({
                    "role": "user",
                    "content": multimodal
                })
                count = record_usage("åœ–ç‰‡")  # é€™è£¡åŒæ™‚ä¹Ÿæœƒç´¯åŠ ä¸€æ¬¡ä½¿ç”¨æ¬¡æ•¸
                model_used = "gpt-4.1"
                response = client_ai.responses.create(
                    model=model_used,  # ä½¿ç”¨å‹•æ…‹æ±ºå®šçš„æ¨¡å‹
                    tools=[
                        {
                        "type": "web_search_preview",
                        "user_location": {
                            "type": "approximate",
                            "country": "TW",
                            "timezone": "Asia/Taipei"
                        },
                        },
                        {"type": "image_generation",
                         "quality": "high",
                        }
                    ],
                    tool_choice={"type": "image_generation"},
                    input=input_prompt,
                )
                replytext = response.output_text
                await send_chunks(message, replytext)
                replyimages = [
                    blk["result"] if isinstance(blk, dict) else blk.result
                    for blk in response.output
                    if (blk["type"] if isinstance(blk, dict) else blk.type) == "image_generation_call"
                ]
                for idx, b64 in enumerate(replyimages):
                    # 1. å…ˆè§£ç¢¼
                    buf = io.BytesIO(base64.b64decode(b64))
                    buf.seek(0)
                    # 2. å›å‚³åˆ° Discord
                    await message.reply(file=discord.File(buf, f"ai_image_{idx+1}.png"))

                input_tokens = response.usage.input_tokens
                output_tokens = response.usage.output_tokens
                total_tokens = response.usage.total_tokens
                await message.reply(f"ğŸ“Š ä»Šå¤©æ‰€æœ‰äººç¸½å…±ä½¿ç”¨ã€Œåœ–ç‰‡ã€åŠŸèƒ½ {count} æ¬¡ï¼Œæœ¬æ¬¡ä½¿ç”¨çš„æ¨¡å‹ï¼š{model_used}+gpt-image-1"
                                    f"\nğŸ“Š token ä½¿ç”¨é‡ï¼š\n"
                                    f"- è¼¸å…¥ tokens: {input_tokens}\n"
                                    f"- å›æ‡‰ tokens: {output_tokens}\n"
                                    f"- ç¸½ token: {total_tokens}"
                                    )
            except Exception as e:
                print(f"[IMG_ERR] user={message.author.id} guild={message.guild.id if message.guild else 'dm'} {type(e).__name__}: {e}")
                await message.reply("âŒ åœ–ç‰‡åŠŸèƒ½ç™¼ç”ŸéŒ¯èª¤ï¼ˆéŒ¯èª¤ä»£ç¢¼ï¼šIMG-001ï¼‰ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
            finally:
                with suppress(discord.HTTPException, discord.Forbidden, discord.NotFound):
                    await thinking.delete()
        elif cmd.startswith("é‡ç½®è¨˜æ†¶"):
            user_id = f"{message.guild.id}-{message.author.id}" if message.guild else f"dm-{message.author.id}"
            await message.reply("âš ï¸ ä½ ç¢ºå®šè¦é‡ç½®è¨˜æ†¶å—ï¼Ÿå»ºè­°åˆ©ç”¨ã€é¡¯ç¤ºè¨˜æ†¶ã€‘æŒ‡ä»¤å‚™ä»½ç›®å‰è¨˜æ†¶ã€‚è‹¥è¦é‡ç½®ï¼Œè«‹å›è¦†ã€Œç¢ºå®šé‡ç½®ã€ï¼›è‹¥è¦å–æ¶ˆï¼Œè«‹å›è¦†ã€Œå–æ¶ˆé‡ç½®ã€ã€‚")
            pending_reset_confirmations[user_id] = True

        elif cmd.startswith("ç¢ºå®šé‡ç½®"):
            user_id = f"{message.guild.id}-{message.author.id}" if message.guild else f"dm-{message.author.id}"
            if pending_reset_confirmations.get(user_id):
                pending_reset_confirmations.pop(user_id)
                state = {
                    "summary": "",
                    "token_accum": 0,
                    "last_response_id": None,
                    "thread_count": 0
                }
                save_user_memory(user_id, state)
                await message.reply("âœ… è¨˜æ†¶å·²é‡ç½®")
            else:
                await message.reply("âš ï¸ æ²’æœ‰å¾…ç¢ºèªçš„é‡ç½®è«‹æ±‚ã€‚")

        elif cmd.startswith("å–æ¶ˆé‡ç½®"):
            user_id = f"{message.guild.id}-{message.author.id}" if message.guild else f"dm-{message.author.id}"
            if pending_reset_confirmations.get(user_id):
                pending_reset_confirmations.pop(user_id)
                await message.reply("å·²å–æ¶ˆè¨˜æ†¶é‡ç½®ã€‚")
            else:
                await message.reply("âš ï¸ æ²’æœ‰å¾…ç¢ºèªçš„é‡ç½®è«‹æ±‚ã€‚")
        elif cmd.startswith("é¡¯ç¤ºè¨˜æ†¶"):
            user_id = f"{message.guild.id}-{message.author.id}" if message.guild else f"dm-{message.author.id}"
            state = load_user_memory(user_id)
            summary = state.get("summary", "")
            if summary:
                await message.reply(f"ğŸ“– ç›®å‰é•·æœŸè¨˜æ†¶æ‘˜è¦ï¼š\n{summary}")
            else:
                await message.reply("ç›®å‰å°šç„¡é•·æœŸè¨˜æ†¶æ‘˜è¦ã€‚")
        elif cmd.startswith("æŒ‡ä»¤é¸å–®"):
            embed = discord.Embed(title="ğŸ“œ Discord Bot æŒ‡ä»¤é¸å–®", color=discord.Color.blue())
            embed.add_field(
                name="â“ å•",
                value="`!å• <å…§å®¹>`\næ”¯æ´åœ–ç‰‡é™„ä»¶å•ç­”ï¼›ä¸»æ¨¡å‹ `gpt-5.2`ï¼Œæ¯ 10 è¼ªä»¥ `gpt-5-nano` åšè¨˜æ†¶æ‘˜è¦ï¼Œä¸¦å•Ÿç”¨ç¶²è·¯æŸ¥è­‰ã€‚",
                inline=False
            )
            embed.add_field(
                name="ğŸ§  å•2ï¼ˆGrokï¼‰",
                value="`!å•2 <å…§å®¹>`\næ”¯æ´åœ–ç‰‡é™„ä»¶å•ç­”ï¼›ä½¿ç”¨ xAI `grok-4-1-fast-reasoning`ï¼Œä¸¦å•Ÿç”¨ function calling / web_search / x_searchï¼ˆéœ€è¨­å®š `XAI_API_KEY`ï¼‰ã€‚",
                inline=False
            )
            embed.add_field(
                name="ğŸ§¹ æ•´ç†",
                value="`!æ•´ç† <ä¾†æºé »é“/è¨è«–ä¸²ID> <æ‘˜è¦é€å‡ºé »é“ID>`\nä½¿ç”¨ `gpt-5.2` æ•´ç†è¿‘ 1000 å‰‡è¨Šæ¯ä¸¦ç™¼é€è‡³æŒ‡å®šé »é“ã€‚",
                inline=False
            )
            embed.add_field(
                name="ğŸ¨ åœ–ç‰‡",
                value="`!åœ–ç‰‡ <æè¿°>`\nä½¿ç”¨ `gpt-4.1 + gpt-image-1` ç”Ÿæˆåœ–ç‰‡ï¼ˆå«ç¶²è·¯æŸ¥è­‰ï¼‰ã€‚",
                inline=False
            )
            embed.add_field(
                name="ğŸ§  é¡¯ç¤ºè¨˜æ†¶",
                value="`!é¡¯ç¤ºè¨˜æ†¶`\né¡¯ç¤ºç›®å‰çš„é•·æœŸè¨˜æ†¶æ‘˜è¦ã€‚",
                inline=False
            )
            embed.add_field(
                name="â™»ï¸ é‡ç½®è¨˜æ†¶",
                value="`!é‡ç½®è¨˜æ†¶` â†’ é–‹å§‹è¨˜æ†¶æ¸…é™¤æµç¨‹\n`!ç¢ºå®šé‡ç½®` / `!å–æ¶ˆé‡ç½®` â†’ ç¢ºèªæˆ–å–æ¶ˆé‡ç½®",
                inline=False
            )
            embed.add_field(
                name="ğŸ“– æŒ‡ä»¤é¸å–®",
                value="`!æŒ‡ä»¤é¸å–®`\né¡¯ç¤ºæœ¬èªªæ˜é¸å–®ã€‚",
                inline=False
            )
            await message.reply(embed=embed)


                
# ===== 7. å•Ÿå‹• Bot =====
client.run(DISCORD_TOKEN)
