import discord
from openai import OpenAI
import os
import requests
import datetime
import fitz  # PyMuPDF
import base64
import psycopg2
from psycopg2.extras import RealDictCursor
import json
import psycopg2
from psycopg2.extras import Json
from psycopg2 import pool
import tiktoken



# ===== 1. è¼‰å…¥ç’°å¢ƒè®Šæ•¸èˆ‡ API é‡‘é‘° =====
DISCORD_TOKEN = os.getenv("DISCORD_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY")
DATABASE_URL = os.getenv("DATABASE_URL")

def load_user_memory(user_id):
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT summary, history, token_accum FROM memory WHERE user_id = %s", (user_id,))
    row = cursor.fetchone()
    db_pool.putconn(conn)
    if row:
        return {
            "summary": row["summary"],
            "history": row["history"],
            "token_accum": row["token_accum"]
        }
    else:
        return {"summary": "", "history": [], "token_accum": 0}


def save_user_memory(user_id, state):
    conn = get_db_connection()  # è‡ªå·±æ‰“é–‹é€£ç·š
    cursor = conn.cursor()
    cursor.execute("""
        INSERT INTO memory (user_id, summary, history, token_accum)
        VALUES (%s, %s, %s, %s)
        ON CONFLICT (user_id) DO UPDATE SET
            summary = EXCLUDED.summary,
            history = EXCLUDED.history,
            token_accum = EXCLUDED.token_accum
    """, (user_id, state["summary"], Json(state["history"]), state["token_accum"]))
    conn.commit()
    db_pool.putconn(conn)

db_pool = pool.SimpleConnectionPool(
    minconn=1,
    maxconn=10,
    dsn=DATABASE_URL,
    cursor_factory=RealDictCursor
)

# ===== 2. è¨­å®šç³»çµ±æç¤ºè©ï¼ˆSystem Promptï¼‰ =====
SYSTEM_PROMPT = (
    "ä½ æ˜¯æ“æœ‰é•·æœŸè¨˜æ†¶çš„ AI åŠ©ç†ï¼Œèƒ½å¤ ç†è§£ä¸¦å»¶çºŒä½¿ç”¨è€…çš„å°è©±æ„åœ–èˆ‡æƒ…å¢ƒã€‚"
    "ç•¶ä½ çœ‹åˆ°ã€è¨˜æ†¶æ‘˜è¦ï¼š...ã€æ™‚ï¼Œè«‹å–„ç”¨é€™æ®µæ‘˜è¦ä¾†ç†è§£ä¸Šä¸‹æ–‡ã€‚"
    "è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œå›ç­”ç°¡æ½”æœ‰æ¢ç†ï¼Œå¿…è¦æ™‚å¯ä»¥è£œå……æ­·å²èƒŒæ™¯æˆ–å»¶çºŒä¹‹å‰çš„è©±é¡Œã€‚"
)


# ===== 3. åˆå§‹åŒ– OpenAI èˆ‡ Perplexity API å®¢æˆ¶ç«¯ =====
client_ai = OpenAI(api_key=OPENAI_API_KEY)
client_perplexity = OpenAI(api_key=PERPLEXITY_API_KEY, base_url="https://api.perplexity.ai")

# ===== 4. å»ºç«‹ Discord Client èˆ‡è¨­å®š intents =====
intents = discord.Intents.default()
intents.message_content = True
intents.messages = True
intents.guilds = True
client = discord.Client(intents=intents)

# ===== 5. è³‡æ–™åº«åˆå§‹åŒ–èˆ‡ä½¿ç”¨è¨˜éŒ„å‡½å¼ =====
def get_db_connection():
    return db_pool.getconn()

def init_db():
    conn = get_db_connection()
    cur = conn.cursor()

    # å»ºç«‹ memory è¡¨
    cur.execute("""
        CREATE TABLE IF NOT EXISTS memory (
            user_id TEXT PRIMARY KEY,
            summary TEXT,
            history JSONB,
            token_accum INTEGER
        )
    """)

    # å»ºç«‹ feature_usage è¡¨
    cur.execute("""
        CREATE TABLE IF NOT EXISTS feature_usage (
            feature TEXT PRIMARY KEY,
            count INTEGER NOT NULL,
            date DATE NOT NULL
        )
    """)

    for feature in ["æ¨ç†", "å•", "æ•´ç†", "æœå°‹"]:
        cur.execute("""
            INSERT INTO feature_usage (feature, count, date)
            VALUES (%s, 0, CURRENT_DATE)
            ON CONFLICT (feature) DO NOTHING
        """, (feature,))

    conn.commit()
    db_pool.putconn(conn)

def record_usage(feature_name):
    conn = get_db_connection()
    cur = conn.cursor()
    today = datetime.date.today()
    cur.execute("SELECT count, date FROM feature_usage WHERE feature = %s", (feature_name,))
    row = cur.fetchone()
    if row:
        if row["date"] != today:
            cur.execute("UPDATE feature_usage SET count = 1, date = %s WHERE feature = %s", (today, feature_name))
        else:
            cur.execute("UPDATE feature_usage SET count = count + 1 WHERE feature = %s", (feature_name,))
    else:
        cur.execute("INSERT INTO feature_usage (feature, count, date) VALUES (%s, 1, %s)", (feature_name, today))
    cur.execute("SELECT count FROM feature_usage WHERE feature = %s", (feature_name,))
    updated = cur.fetchone()["count"]
    conn.commit()
    db_pool.putconn(conn)
    return updated

def is_usage_exceeded(feature_name, limit=20):
    conn = get_db_connection()
    cur = conn.cursor()
    today = datetime.date.today()
    cur.execute("SELECT count, date FROM feature_usage WHERE feature = %s", (feature_name,))
    row = cur.fetchone()
    db_pool.putconn(conn)
    if row:
        return row["date"] == today and row["count"] >= limit
    return False

# ===== 6. Discord äº‹ä»¶ç¶å®š =====
@client.event
async def on_ready():
    init_db()
    print(f'âœ… Bot ç™»å…¥æˆåŠŸï¼š{client.user}')

ENCODER = tiktoken.encoding_for_model("gpt-4o-mini")

def count_tokens(text):
    return len(ENCODER.encode(text))

def summarize_history(history):
    history_text = "\n".join(f"{m['role']}: {m['content']}" for m in history)
    response = client_ai.responses.create(
        model="gpt-4o-mini",
        input=[
            {"role": "system", "content": "è«‹å°‡ä»¥ä¸‹å¤šè¼ªå°è©±è½‰æ›ç‚º AI åŠ©ç†å¯ä»¥ç†è§£çš„é•·æœŸè¨˜æ†¶å…§å®¹ï¼Œ"
                                        "è«‹ä»¥å‚™å¿˜éŒ„å½¢å¼ç°¡è¿°ä½¿ç”¨è€…çš„å€‹æ€§ã€æå•ä¸»é¡Œã€èƒŒæ™¯è³‡è¨Šã€èªæ°£èˆ‡éœ€æ±‚ã€‚"},
            {"role": "user", "content": history_text}
        ],
        max_output_tokens=500
    )
    return response.output_text

@client.event
async def on_message(message):
    if message.author == client.user:
        return

    commands = message.content.split("!")
    for cmd in commands:
        if not cmd.strip():
            continue

        # --- åŠŸèƒ½ 1ï¼šæ¨ç† ---
        if cmd.startswith("æ¨ç† "):
            prompt = cmd[3:].strip()
            thinking_message = await message.reply("ğŸ§  Thinking...")
            try:
                if message.guild:
                    user_id = f"{message.guild.id}-{message.author.id}"
                else:
                    user_id = f"dm-{message.author.id}"

                state = load_user_memory(user_id)

                # åŠ å…¥ç•¶å‰æå•
                state["history"].append({"role": "user", "content": prompt})
                state["token_accum"] += count_tokens(prompt)

                # å¦‚ç´¯ç©è¶…é 4000 tokenï¼Œé€²è¡Œæ‘˜è¦
                if state["token_accum"] >= 4000:
                    state["summary"] = summarize_history(state["history"])
                    state["history"] = []
                    state["token_accum"] = 0

                # çµ„åˆ input
                input_content = [{"role": "system", "content": SYSTEM_PROMPT}]
                if state["summary"]:
                    input_content.append({"role": "assistant", "content": f"è¨˜æ†¶æ‘˜è¦ï¼š{state['summary']}"} )
                input_content += state["history"] + [{"role": "user", "content": prompt}]

                response = client_ai.responses.create(
                    model="o3-mini",  # æ”¹æˆ o3-mini å¦‚æœæ˜¯æ¨ç†
                    input=input_content,
                    max_output_tokens=2500,
                )
                reply = response.output_text
                state["history"].append({"role": "assistant", "content": reply})
                save_user_memory(user_id, state)
                await message.reply(reply)
                count = record_usage("æ¨ç†")
                await message.reply(f"ğŸ“Š ä»Šå¤©æ‰€æœ‰äººç¸½å…±ä½¿ç”¨ã€Œæ¨ç†ã€åŠŸèƒ½ {count} æ¬¡")
            except Exception as e:
                await message.reply(f"âŒ AI äº’å‹•æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            finally:
                await thinking_message.delete()

        # --- åŠŸèƒ½ 2ï¼šå•ç­”ï¼ˆå«åœ–ç‰‡èˆ‡ PDFï¼‰ ---
        elif cmd.startswith("å• "):
            prompt = cmd[2:].strip()
            thinking_message = await message.reply("ğŸ§  Thinking...")

            try:
                if message.guild:
                    user_id = f"{message.guild.id}-{message.author.id}"
                else:
                    user_id = f"dm-{message.author.id}"

                state = load_user_memory(user_id)

                # åŠ å…¥ç›®å‰æå•
                state["history"].append({"role": "user", "content": prompt})
                state["token_accum"] += count_tokens(prompt)

                # è§¸ç™¼æ‘˜è¦
                if state["token_accum"] >= 4000:
                    state["summary"] = summarize_history(state["history"])
                    state["history"] = []
                    state["token_accum"] = 0

                # ==== è™•ç†åœ–ç‰‡ / PDF é™„ä»¶ ====
                multimodal_content = [{"type": "input_text", "text": prompt}]

                for attachment in message.attachments[:3]:
                    if attachment.content_type and attachment.content_type.startswith("image/"):
                        multimodal_content.append({
                            "type": "input_image",
                            "image_url": attachment.url,
                            "detail": "auto"
                        })

                for attachment in message.attachments:
                    if attachment.filename.endswith(".pdf") and attachment.size < 30 * 1024 * 1024:
                        pdf_bytes = await attachment.read()
                        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
                        pdf_text = ""
                        for page_num in range(min(5, len(doc))):
                            page = doc.load_page(page_num)
                            pdf_text += page.get_text()

                        multimodal_content.append({
                            "type": "input_text",
                            "text": f"[å‰5é PDFå…§å®¹æ‘˜è¦é–‹å§‹]\n{pdf_text[:3000]}\n[æ‘˜è¦çµæŸ]"
                        })

                        encoded_pdf = base64.b64encode(pdf_bytes).decode("utf-8")
                        multimodal_content.append({
                            "type": "input_file",
                            "filename": attachment.filename,
                            "file_data": f"data:application/pdf;base64,{encoded_pdf}",
                        })

                # ==== çµ„åˆå®Œæ•´è¼¸å…¥ ====
                input_content = [{"role": "system", "content": SYSTEM_PROMPT}]
                if state["summary"]:
                    input_content.append({"role": "assistant", "content": f"è¨˜æ†¶æ‘˜è¦ï¼š{state['summary']}"} )
                input_content += state["history"]
                input_content.append({"role": "user", "content": multimodal_content})

                # ==== ç™¼é€è«‹æ±‚ ====
                response = client_ai.responses.create(
                    model="gpt-4o-mini",
                    input=input_content,
                    max_output_tokens=5000,
                    temperature=1.0
                )
                reply = response.output_text

                # ==== å„²å­˜ä¸¦å›è¦† ====
                state["history"].append({"role": "assistant", "content": reply})
                save_user_memory(user_id, state)
                await message.reply(reply)

                count = record_usage("å•")
                await message.reply(f"ğŸ“Š ä»Šå¤©æ‰€æœ‰äººç¸½å…±ä½¿ç”¨ã€Œå•ã€åŠŸèƒ½ {count} æ¬¡")
            except Exception as e:
                await message.reply(f"âŒ AI äº’å‹•æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            finally:
                await thinking_message.delete()

        # --- åŠŸèƒ½ 3ï¼šå…§å®¹æ•´ç†æ‘˜è¦ ---
        elif cmd.startswith("æ•´ç† "):
            parts = cmd.split()
            if len(parts) != 3 or not parts[1].isdigit() or not parts[2].isdigit():
                await message.reply("âš ï¸ ä½¿ç”¨æ–¹æ³•ï¼š`!æ•´ç† <ä¾†æºé »é“/è¨è«–ä¸²ID> <æ‘˜è¦è¦é€åˆ°çš„é »é“ID>`")
                continue

            source_id = int(parts[1])
            summary_channel_id = int(parts[2])
            await message.reply(f"ğŸ” æ­£åœ¨æœå°‹ä¾†æº ID `{source_id}` èˆ‡ç›®æ¨™é »é“ ID `{summary_channel_id}`...")

            source_channel = client.get_channel(source_id)
            summary_channel = client.get_channel(summary_channel_id)
            if not isinstance(source_channel, (discord.Thread, discord.TextChannel)) or not isinstance(summary_channel, discord.TextChannel):
                await message.reply("âš ï¸ æ‰¾ä¸åˆ°ä¾†æºæˆ–ç›®æ¨™é »é“ï¼Œè«‹ç¢ºèª bot æ¬Šé™èˆ‡ ID æ˜¯å¦æ­£ç¢ºã€‚")
                continue

            await message.reply("ğŸ§¹ æ­£åœ¨æ•´ç†å…§å®¹ï¼Œè«‹ç¨å¾Œ...")
            try:
                messages_history = [msg async for msg in source_channel.history(limit=50)]
                conversation = "\n".join(f"{msg.author.display_name}: {msg.content}" for msg in reversed(messages_history))
                source_type = f"è¨è«–ä¸²ï¼š{source_channel.name}" if isinstance(source_channel, discord.Thread) else f"é »é“ï¼š{source_channel.name}"

                response = client_ai.responses.create(
                    model="gpt-4o-mini",
                    input=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æ“…é•·å…§å®¹æ‘˜è¦çš„åŠ©ç†ï¼Œè«‹æ•´ç†ä»¥ä¸‹ Discord è¨Šæ¯æˆç‚ºæ¢ç†æ¸…æ¥šã€æ˜“è®€çš„æ‘˜è¦ã€‚"},
                        {"role": "user", "content": conversation}
                    ]
                )

                summary = response.output_text
                embed = discord.Embed(title=f"å…§å®¹æ‘˜è¦ï¼š{source_type}", description=summary, color=discord.Color.blue())
                embed.set_footer(text=f"ä¾†æºID: {source_id}")
                await summary_channel.send(embed=embed)
                await message.reply("âœ… å…§å®¹æ‘˜è¦å·²ç¶“ç™¼é€ï¼")

                count = record_usage("æ•´ç†")
                await message.reply(f"ğŸ“Š ä»Šå¤©æ‰€æœ‰äººç¸½å…±ä½¿ç”¨ã€Œæ•´ç†ã€åŠŸèƒ½ {count} æ¬¡")
            except Exception as e:
                await message.reply(f"âŒ æ‘˜è¦æ•´ç†æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        # --- åŠŸèƒ½ 4ï¼šæœå°‹æŸ¥è©¢ ---
        elif cmd.startswith("æœå°‹ "):
            if is_usage_exceeded("æœå°‹", limit=20):
                await message.reply("âš ï¸ ä»Šå¤©æœå°‹æ¬¡æ•¸å·²é”ä¸Šé™ï¼ˆ20æ¬¡ï¼‰ï¼Œè«‹æ˜å¤©å†è©¦ã€‚")
                continue
            query = cmd[2:].strip()

            thinking_message = await message.reply("ğŸ” æœå°‹ä¸­...")
            try:
                payload = {
                    "model": "sonar",
                    "messages": [
                        {
                            "role": "system",
                            "content": "ä½ å…·å‚™è±å¯Œæƒ…ç·’èˆ‡æºé€šèƒ½åŠ›ï¼Œèƒ½ä¾å°è©±å…§å®¹çµ¦äºˆæœ‰è¶£å›æ‡‰ï¼Œä¸¦ä»¥å°ˆæ¥­å­¸ç§‘åˆ†é¡ç°¡æ˜è§£ç­”å•é¡Œã€‚ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œå›ç­”ç²¾ç°¡æœ‰é‡é»ï¼Œæ§åˆ¶åœ¨200å­—å…§ï¼Œé©åº¦æä¾›çœŸå¯¦å°ºåº¦çš„åˆ†æï¼Œä¸¦é¡¯ç¤º input/output token ä½¿ç”¨é‡ã€‚"
                        },
                        {"role": "user", "content": query}
                    ],
                    "max_tokens": 1000,
                    "temperature": 1.2,
                    "top_p": 0.9,
                    "top_k": 0,
                    "stream": False,
                    "presence_penalty": 0,
                    "frequency_penalty": 1,
                    " response_format": {},
                    "web_search_options": {"search_context_size": "low"}
                }
                headers = {
                    "Authorization": f"Bearer {PERPLEXITY_API_KEY}",
                    "Content-Type": "application/json"
                }
                response = requests.post("https://api.perplexity.ai/chat/completions", json=payload, headers=headers)
                if response.status_code == 200:
                    data = response.json()
                    reply = data["choices"][0]["message"]["content"]
                    await message.reply(reply)

                    count = record_usage("æœå°‹")
                    await message.reply(f"ğŸ“Š ä»Šå¤©æ‰€æœ‰äººç¸½å…±ä½¿ç”¨ã€Œæœå°‹ã€åŠŸèƒ½ {count} æ¬¡")
                else:
                    await message.reply(f"âŒ æœå°‹æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼ŒHTTP ç‹€æ…‹ç¢¼ï¼š{response.status_code}")
            except Exception as e:
                await message.reply(f"âŒ æœå°‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            finally:
                await thinking_message.delete()
                
# ===== 7. å•Ÿå‹• Bot =====
client.run(DISCORD_TOKEN)
